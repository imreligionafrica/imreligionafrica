{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be34c8ad-b518-47f9-832b-0871508e159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import wasserstein_distance, energy_distance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f31d7dd-0daf-4b17-8735-9be8d664d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = globals()['_dh'][0] \n",
    "df = pd.read_csv(os.path.join(os.path.dirname(cwd), 'data', 'ysc0_distributions_by_district_bd.csv'))\n",
    "df = df[(~pd.isnull(df.district)) & (~pd.isnull(df.bd))].reset_index(drop=True)\n",
    "df = df.fillna(0)\n",
    "df['wy0sum'] = df.groupby(['iso', 'district', 'bd', 'major_religion'])['wy0'].transform('sum')\n",
    "df['wy01418sum'] = df.groupby(['iso', 'district', 'bd', 'major_religion'])['wy01418'].transform('sum')\n",
    "df['wy0'] = df.wy0 / df.wy0sum\n",
    "df['wy01418'] = df.wy01418 / df.wy01418sum\n",
    "df = df.drop(['wy0sum', 'wy01418sum'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18971c1-cbfd-4369-8742-c5d7a192d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_dists = df[['iso', 'district']].drop_duplicates(['iso', 'district']).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3cc836-ddd8-4105-a923-8f3b5a0e3b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "1500.0\n",
      "2500.0\n"
     ]
    }
   ],
   "source": [
    "outlist = []\n",
    "\n",
    "# for district in range(1,10):\n",
    "for district in sorted(list(set(df.district))):\n",
    "    if district % 500 == 0:\n",
    "        print(district)\n",
    "    sub_df = df[df.district==district]\n",
    "    for bd in set(sub_df.bd):\n",
    "        sub_sub_df = (sub_df[sub_df.bd==bd][\n",
    "                        ['ysc0', 'major_religion', 'wy0', 'wy01418']]\n",
    "                        .set_index(['ysc0', 'major_religion'], drop=True)\n",
    "                        .unstack()\n",
    "                        .fillna(0)\n",
    "                     )\n",
    "        try:\n",
    "            w_all_m = wasserstein_distance(sub_sub_df.index, \n",
    "                                           sub_sub_df.index, \n",
    "                                           u_weights=sub_sub_df['wy0']['Christian'].values, \n",
    "                                           v_weights=sub_sub_df['wy0']['Muslim'].values)      \n",
    "        except:\n",
    "            w_all_m = np.nan\n",
    "        try:\n",
    "            w_all_t = wasserstein_distance(sub_sub_df.index, \n",
    "                                           sub_sub_df.index, \n",
    "                                           u_weights=sub_sub_df['wy0']['Christian'].values, \n",
    "                                           v_weights=sub_sub_df['wy0']['Traditional'].values)      \n",
    "        except:\n",
    "            w_all_t = np.nan              \n",
    "              \n",
    "              \n",
    "        try:\n",
    "            w_1418_m = wasserstein_distance(sub_sub_df.index, \n",
    "                                            sub_sub_df.index, \n",
    "                                            u_weights=sub_sub_df['wy01418']['Christian'].values, \n",
    "                                            v_weights=sub_sub_df['wy01418']['Muslim'].values)\n",
    "        except:\n",
    "            w_1418_m = np.nan     \n",
    "              \n",
    "        try:\n",
    "            w_1418_t = wasserstein_distance(sub_sub_df.index, \n",
    "                                            sub_sub_df.index, \n",
    "                                            u_weights=sub_sub_df['wy01418']['Christian'].values, \n",
    "                                            v_weights=sub_sub_df['wy01418']['Traditional'].values)\n",
    "        except:\n",
    "            w_1418_t = np.nan   \n",
    "              \n",
    "              \n",
    "     \n",
    "        outlist.append([district, bd, w_all_m, w_all_t, w_1418_m, w_1418_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08150198-a557-4a04-9af2-27903da814c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame(outlist, columns=['district', 'bd', 'w_all_m', 'w_all_t', 'w_1418_m', 'w_1418_t'])\n",
    "out = pd.merge(iso_dists, out, on=['district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a2b4b2e-5a80-4b90-9aae-cf4be0be48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_m = out[['iso', 'district', 'bd', 'w_all_m']].dropna()\n",
    "out_all_t = out[['iso', 'district', 'bd', 'w_all_t']].dropna()\n",
    "out_1418_m = out[['iso', 'district', 'bd', 'w_1418_m']].dropna()\n",
    "out_1418_t = out[['iso', 'district', 'bd', 'w_1418_t']].dropna()\n",
    "\n",
    "out_all_m.sort_values(['bd', 'w_all_m'], inplace=True)\n",
    "out_all_m['r_all_m'] = out_all_m.groupby('bd').agg('iso').cumcount() + 1\n",
    "out_all_m.sort_values(['bd', 'iso', 'w_all_m'], inplace=True)\n",
    "out_all_m['r_all_m_byc'] = out_all_m.groupby(['bd', 'iso']).agg('iso').cumcount() + 1\n",
    "out_all_m['n_all_m_byc'] = out_all_m.groupby(['bd', 'iso']).agg('iso').transform('count')\n",
    "\n",
    "\n",
    "out_all_t.sort_values(['bd', 'w_all_t'], inplace=True)\n",
    "out_all_t['r_all_t'] = out_all_t.groupby('bd').agg('iso').cumcount() + 1\n",
    "out_all_t.sort_values(['bd', 'iso', 'w_all_t'], inplace=True)\n",
    "out_all_t['r_all_t_byc'] = out_all_t.groupby(['bd', 'iso']).agg('iso').cumcount() + 1\n",
    "out_all_t['n_all_t_byc'] = out_all_t.groupby(['bd', 'iso']).agg('iso').transform('count')\n",
    "\n",
    "\n",
    "out_1418_m.sort_values(['bd', 'w_1418_m'], inplace=True)\n",
    "out_1418_m['r_1418_m'] = out_1418_m.groupby('bd').agg('iso').cumcount() + 1\n",
    "out_1418_m.sort_values(['bd', 'iso', 'w_1418_m'], inplace=True)\n",
    "out_1418_m['r_1418_m_byc'] = out_1418_m.groupby(['bd', 'iso']).agg('iso').cumcount() + 1\n",
    "out_1418_m['n_1418_m_byc'] = out_1418_m.groupby(['bd', 'iso']).agg('iso').transform('count')\n",
    "\n",
    "\n",
    "out_1418_t.sort_values(['bd', 'w_1418_t'], inplace=True)\n",
    "out_1418_t['r_1418_t'] = out_1418_t.groupby('bd').agg('iso').cumcount() + 1\n",
    "out_1418_t.sort_values(['bd', 'iso', 'w_1418_t'], inplace=True)\n",
    "out_1418_t['r_1418_t_byc'] = out_1418_t.groupby(['bd', 'iso']).agg('iso').cumcount() + 1\n",
    "out_1418_t['n_1418_t_byc'] = out_1418_t.groupby(['bd', 'iso']).agg('iso').transform('count')\n",
    "\n",
    "\n",
    "out = pd.merge(out_all_m, out_all_t, on=['iso', 'district', 'bd'], how='outer')\n",
    "out = pd.merge(out, out_1418_m, on=['iso', 'district', 'bd'], how='outer')\n",
    "out = pd.merge(out, out_1418_t, on=['iso', 'district', 'bd'], how='outer')\n",
    "\n",
    "out = out.set_index(['bd', 'district'], drop=True)\n",
    "out.to_csv(os.path.join(os.path.dirname(cwd), 'data', '_distribution_similarity_y0_mct_bd.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "4dc5d84d173dc1171a3b7987f7238db85e775472178a8ee1f3827b7e8efb7280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
